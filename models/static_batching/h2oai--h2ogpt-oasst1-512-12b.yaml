deployment_config:
  autoscaling_config:
    min_replicas: 1
    initial_replicas: 1
    max_replicas: 8
    target_num_ongoing_requests_per_replica: 1.0
    metrics_interval_s: 10.0
    look_back_period_s: 30.0
    smoothing_factor: 1.0
    downscale_delay_s: 300.0
    upscale_delay_s: 90.0
  ray_actor_options:
    resources:
      accelerator_type_cpu: 0.01
model_config:
  batching: static
  model_id: h2oai/h2ogpt-oasst1-512-12b
  max_input_words: 800
  initialization:
    s3_mirror_config:
      bucket_uri: s3://large-dl-models-mirror/models--h2oai--h2ogpt-oasst1-512-12b/main-safetensors/
      s3_sync_args:
        - "--no-sign-request"
    initializer:
      type: DeepSpeed
      dtype: float16
      from_pretrained_kwargs:
        trust_remote_code: true
        use_cache: true
      use_kernel: true
      max_tokens: 1536
    pipeline: transformers
  generation:
    max_batch_size: 4
    generate_kwargs:
      do_sample: true
      num_beams: 1
      max_new_tokens: 512
      min_new_tokens: 16
      temperature: 0.2
      top_p: 0.85
      top_k: 70
      repetition_penalty: 1.07
    prompt_format:
      system: "{instruction}\n"
      assistant: "<bot>: {instruction}\n"
      trailing_assistant: "<bot>: "
      user: "<human>: {instruction}\n"
      default_system_message: "<bot>: I am an intelligent, helpful, truthful, and fair assistant named h2oGPT, who will give accurate, balanced, and reliable responses. I will not respond with I don't know or I don't understand.\n<human>: I am a human person seeking useful assistance and request all questions be answered completely, and typically expect detailed responses. Give answers in numbered list format if several distinct but related items are being listed."
    stopping_sequences: [[29, 13961, 32056], [29, 12042, 32056]]
scaling_config:
  num_workers: 2
  num_gpus_per_worker: 1
  num_cpus_per_worker: 4
  resources_per_worker:
    accelerator_type_a10: 0.01
