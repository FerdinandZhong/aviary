name: your_anyscale_servie_name
project_id: optional_project_id
cluster_env:  cluster_environment_name:version
compute_config: compute_config_name
ray_serve_config:
  import_path: aviary.backend:llm_application
  runtime_env:
    # This working dir is relative to the working dir when we run this file
    working_dir: "."
    excludes: 
    - "deploy"
    - "aviary/frontend"
    - "**.DS_Store"
    - ".git"
  args:
    models:
    # This can be a path to a model configuration directory or yaml
    # Or it can directly define your LLMApp inline
    # This directory must exist at runtime on the cluster
    - ./models
